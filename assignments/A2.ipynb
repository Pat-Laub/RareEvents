{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rare-event simulation\n",
    "\n",
    "### Assignment 2\n",
    "\n",
    "Due: Wednesday, March 24, 1:30 pm\n",
    "\n",
    "Submission by email, send completed Jupyter notebook. \n",
    "\n",
    "Date: March 10, 2020\n",
    "\n",
    "Corrections: March 14, 2020"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider the portfolio loss incurred from defaults,\n",
    "\n",
    "$$ L(\\boldsymbol{X}) = c_1 1\\{X_1 > x_1\\} + \\dots c_n 1\\{X_n > x_n\\} $$\n",
    "\n",
    "where the $c_i$'s are the size of the outstanding loan to obliger $i$, and $1\\{ X_i > x_i \\}$ represents the random indicator for whether or not obliger $i$ will default on their loan. \n",
    "\n",
    "Here $X_i$ somewhat represents the level of financial strain for obliger $i$. This reflects the individual (\"idiosyncratic\") situation for each obliger, but all obligers are equally affected by broad economic swings. We model these separately, so\n",
    "\n",
    "$$ X_i = \\sqrt{(1-\\rho)} \\eta_i + \\sqrt{\\rho} Z $$\n",
    "\n",
    "where $\\rho \\in (-1,1)$ specifies the $\\mathbb{C}\\mathrm{orr}(X_i,X_j)$, $Z \\sim \\mathsf{Normal}(0,1)$ are shared between all obligers, and $\\eta_i \\overset{\\mathrm{i.i.d.}}{\\sim} \\mathsf{Normal}(0, 1)$ is the idiosyncratic variable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This problem is inspired by Section 5 of [Chan and Kroese (2011)](http://joshuachan.org/papers/impCE2.pdf), though I have simplified it a bit. This paper is extremely well written, I'd recommend taking a look for more explanation & context."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The main goal is to use crude Monte Carlo, cross-entropy method, and the improved cross-entropy method (with MCMC samples) to estimate\n",
    "\n",
    "$$ \\ell = \\mathbb{P}(L(\\boldsymbol{X}) > \\gamma) \\,.$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start by importing some packages and defining the constants for our particular problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import arviz as az\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import numpy.random as rnd\n",
    "from scipy import stats\n",
    "from tqdm.notebook import trange, tqdm\n",
    "%config InlineBackend.figure_format = 'retina'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 10\n",
    "ρ = 0.5\n",
    "cs = np.exp(0.2 * np.arange(n))\n",
    "xs = np.exp(0.2 * np.arange(n))\n",
    "γ = 0.75 * np.sum(cs)\n",
    "print(\"c:\", list(cs))\n",
    "print(\"x:\", list(xs))\n",
    "print(\"γ:\", γ)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'll supply the code for a (very) crude Monte Carlo run using a small number of $R$ replications. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time \n",
    "\n",
    "rng = rnd.default_rng(1)\n",
    "R = 10**6\n",
    "\n",
    "ηs = rng.normal(size=(R, n))\n",
    "Zs = rng.normal(size=(R, 1))\n",
    "Xs = np.sqrt(1-ρ) * ηs + np.sqrt(ρ) * Zs\n",
    "\n",
    "defaults = Xs > xs\n",
    "losses = np.dot(defaults, cs)\n",
    "\n",
    "ests = losses > γ\n",
    "\n",
    "ℓHat = ests.mean()\n",
    "σHat = ests.std()\n",
    "widthCI = 1.96 * σHat / np.sqrt(R)\n",
    "print(f\"CMC estimate:\\t {ℓHat} (+/- {widthCI})\")\n",
    "print(f\"CMC low bound:\\t {np.maximum(ℓHat-widthCI, 0)}\")\n",
    "print(f\"CMC upp bound:\\t {ℓHat+widthCI}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Big crude Monte Carlo__\n",
    "\n",
    "1) Run repeated crude Monte Carlo tests, as in the code demonstrations, so that in total you have a combined CMC test with $R=10^9$ iterations. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time \n",
    "\n",
    "rng = rnd.default_rng(2)\n",
    "R = 10**9\n",
    "\n",
    "# ADD CODE HERE\n",
    "\n",
    "\n",
    "print(f\"CMC estimate:\\t {ℓHat} (+/- {widthCI})\")\n",
    "print(f\"CMC low bound:\\t {np.maximum(ℓHat-widthCI, 0)}\")\n",
    "print(f\"CMC upp bound:\\t {ℓHat+widthCI}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Improved cross-entropy method__\n",
    "\n",
    "2) Use MCMC to sample $\\boldsymbol{\\eta} = (\\eta_1, \\dots, \\eta_n)$ and $Z$ conditionally on the event that $L(\\boldsymbol{X}) > \\gamma$ where $\\boldsymbol{X} \\equiv \\boldsymbol{X}(\\boldsymbol{\\eta}, Z)$. Use the random walk sampler where each jump is an $n+1$ dimensional vector of i.i.d. normal random variables. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note, if we say $\\boldsymbol{X} \\equiv \\boldsymbol{X}(\\boldsymbol{\\eta}, Z)$, then the target density in terms of $\\boldsymbol{\\eta}$ and $Z$ is\n",
    "\n",
    "$$ \\pi(\\boldsymbol{\\eta}, Z) = \\frac{1}{\\ell} 1\\bigl\\{ L( \\boldsymbol{X}(\\boldsymbol{\\eta}, Z) ) > \\gamma \\bigr\\} \\, \\phi(Z) \\prod_{i=1}^n \\phi(\\eta_i)   $$\n",
    "\n",
    "where $\\phi$ is the p.d.f. of a standard normal distribution. Since we don't need proportionality constants, we can instead use\n",
    "\n",
    "$$ \\pi(\\eta, Z) = 1\\bigl\\{ L( \\boldsymbol{X}(\\boldsymbol{\\eta}, Z) ) > \\gamma \\bigr\\} \\exp\\Bigl\\{ - \\frac{Z^2}{2} \\Bigr\\} \\prod_{i=1}^n \\exp\\Bigl\\{ - \\frac{\\eta_i^2}{2} \\Bigr\\} \\,.  $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time \n",
    "\n",
    "rng = rnd.default_rng(3)\n",
    "R = 10**6\n",
    "\n",
    "# ADD CODE HERE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3) Print out the traceplots for $\\eta_1$ and $Z$. Throw away some burn in samples if you decide it is necessary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4) Calculate the effective sample size (ESS) for your $Z$ samples and make sure that your $R$ is large enough so that this ESS is at least 1000. If it is too small, go back and update the previous cells until this constraint is reached. If this takes a long time, try playing with the scale parameter for the MCMC jumps. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5) Use the arviz `plot_posterior` function to visualise the $\\eta_0$ samples, again for the $\\eta_n$ samples, and again for the $Z$ samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6) Calculate the overall sample mean $\\overline{\\eta}$ of the $\\boldsymbol{\\eta}$ samples (i.e. just one number for the mean of the $R \\times n$ matrix of samples), and the sample mean $\\overline{Z}$ of the $Z$ samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7) Run importance sampling with $R=10^6$ samples where we sample each $\\eta_i$ from a $\\mathsf{Normal}(\\overline{\\eta}, 1)$ distribution and each $Z$ from a $\\mathsf{Normal}(\\overline{Z}, 1)$ distribution. This is the improved cross-entropy estimate. Print the result and the confidence interval. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time \n",
    "\n",
    "rng = rnd.default_rng(5)\n",
    "R = 10**6\n",
    "\n",
    "# ADD CODE HERE\n",
    "\n",
    "\n",
    "print(f\"ICE estimate:\\t {ℓHat} (+/- {widthCI})\")\n",
    "print(f\"ICE low bound:\\t {ℓHat-widthCI}\")\n",
    "print(f\"ICE upp bound:\\t {ℓHat+widthCI}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Cross entropy__\n",
    "\n",
    "The problem above is particularly hard for the traditional CE method (this is probably why the authors chose it to compare their 'improved' version against it). Let's consider the same problem except the loss will instead be\n",
    "\n",
    "$$ L(\\boldsymbol{X}) = X_1 1\\{X_1 > x_1\\} + \\dots X_n 1\\{X_n > x_n\\} \\,.$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are the constants we'll use for this question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 3\n",
    "ρ = 0.5\n",
    "xs = np.exp(0.15 * np.arange(n))\n",
    "γ = 1.5 * np.sum(xs)\n",
    "print(\"x:\", list(xs))\n",
    "print(\"γ:\", γ)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8) Use the original cross-entropy algorithm to find a good proposal distribution. Look inside the family of distributions where $\\eta_n \\sim \\mathsf{Normal}(\\overline{\\eta}_n, 1)$ (note, the other $\\eta_i$'s are unchanged) and where $Z \\sim \\mathsf{Normal}(\\overline{Z}, 1)$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "rng = rnd.default_rng(6)\n",
    "R = 10**6\n",
    "\n",
    "maxIter = 20\n",
    "ρ = 0.05\n",
    "v = (0, 0)\n",
    "\n",
    "for iterNum in range(maxIter):\n",
    "    print(v)\n",
    "    \n",
    "    # ADD CODE HERE\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9) Run importance sampling with this proposal to get the cross-entropy estimate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time \n",
    "rng = rnd.default_rng(1234)\n",
    "R = 10**6\n",
    "\n",
    "# ADD CODE HERE\n",
    "\n",
    "print(f\"CE estimate:\\t {ℓHatCE} (+/- {widthCICE})\")\n",
    "print(f\"CE low bound:\\t {ℓHatCE-widthCICE}\")\n",
    "print(f\"CE upp bound:\\t {ℓHatCE+widthCICE}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:root] *",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
